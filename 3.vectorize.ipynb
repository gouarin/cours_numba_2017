{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisation de vectorize et guvectorize\n",
    "\n",
    "<img src=\"figures/numba_blue_icon_rgb.png\" alt=\"Drawing\" style=\"width: 20%;\"/>\n",
    "\n",
    "<center>**Loic Gouarin**</center>\n",
    "<center>*8 novembre 2017*</center>\n",
    "\n",
    "Numba fournie deux autres fonctionalités (**vectorize** et **guvectorize**) permettant d'accélérer des fonctions universelles NumPy ([ufuncs](https://docs.scipy.org/doc/numpy/reference/ufuncs.html)). Avant d'aller plus loin, rappelons ce qu'est une ufunc.\n",
    "\n",
    "Une ufunc est une fonction qui agit élément par élément pour un tableau donné. Elle permet de vectoriser les opérations et elle est définie de la manière suivante: les paramètres d'entrée sont des scalaires et le paramètre de sortie est également un scalaire. \n",
    "\n",
    "Prenons par exemple la fonction heaviside qui est définie de la manière suivante\n",
    "\n",
    "$$\n",
    "heaviside(x, h_0) = \n",
    "\\left\\{\n",
    "\\begin{array}{l}\n",
    "0 \\; \\text{si} \\; x<0, \\\\\n",
    "h_0 \\; \\text{si} \\; x=0, \\\\\n",
    "1 \\; \\text{si} \\; x>0.\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Les ufuncs sont codées en C dans NumPy et sont donc optimisées. Voici la version de la fonction heaviside dans NumPy (attention, cette fonction n'est disponible qu'à partir de la dernière version: 1.13)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C\n",
    "/**begin repeat\n",
    " * #type = npy_float, npy_double, npy_longdouble#\n",
    " * #c = f, ,l#\n",
    " * #C = F, ,L#\n",
    " */\n",
    "\n",
    "@type@ npy_heaviside@c@(@type@ x, @type@ h0)\n",
    "{\n",
    "    if (npy_isnan(x)) {\n",
    "        return (@type@) NPY_NAN;\n",
    "    }\n",
    "    else if (x == 0) {\n",
    "        return h0;\n",
    "    }\n",
    "    else if (x < 0) {\n",
    "        return (@type@) 0.0;\n",
    "    }\n",
    "    else {\n",
    "        return (@type@) 1.0;\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vous pouvez le voir ce n'est pas très lisible et surtout, vous n'avez certainement pas envie de faire une interface C pour une fonction simple.\n",
    "\n",
    "**vectorize** et **guvectorize** sont donc là pour vous aider à construire des ufuncs tout en restant en Python.\n",
    "\n",
    "## vectorize\n",
    "\n",
    "Voici comment la fonction heaviside s'écrit en Numba en utilisant **vectorize**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "\n",
    "@vectorize(['float64(float64, float64)'])\n",
    "def heaviside(x, h0):\n",
    "    if x == 0:\n",
    "        return h0\n",
    "    elif x < 0:\n",
    "        return 0.\n",
    "    else:\n",
    "        return 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = -1 + 2*np.random.random(1000000)\n",
    "h0 = .4 \n",
    "numba_res = heaviside(x, h0)\n",
    "numpy_res = np.heaviside(x, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(numba_res == numpy_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.65 ms ± 229 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit heaviside(x, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.25 ms ± 39.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.heaviside(x, h0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction Numba est plus lente que la fonction NumPy. On peut accélérer un peu les choses en spécifiant la cible. En effet, **vectorize** a un mot clé **target** indiquant\n",
    "\n",
    "- 'cpu'\n",
    "\n",
    "fonction pour un thread sur CPU\n",
    "\n",
    "- 'parallel'\n",
    "\n",
    "fonction multi-threads pour CPU\n",
    "\n",
    "- 'cuda'\n",
    "\n",
    "fonction utilisant cuda sur GPU\n",
    "\n",
    "Voyons ce que ça donne si nous mettons cette fonction en parallèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize(['float64(float64, float64)'], target='parallel')\n",
    "def heaviside_para(x, h0):\n",
    "    if x == 0:\n",
    "        return h0\n",
    "    elif x < 0:\n",
    "        return 0.\n",
    "    else:\n",
    "        return 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On l'appelle une première fois pour ne pas prendre en compte le temps de compilation dans le calcul de la performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numba_res_para = heaviside_para(x, h0)\n",
    "np.all(numba_res_para == numpy_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.54 ms ± 66.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit heaviside_para(x, h0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous sommes cette fois un peu plus rapide que la fonction NumPy. Mais il faut noté que la version NumPy n'est pas parallèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@vectorize(['float64(float64, float64)'], target='cuda')\n",
    "def heaviside_gpu(x, h0):\n",
    "    if x == 0:\n",
    "        return h0\n",
    "    elif x < 0:\n",
    "        return 0.\n",
    "    else:\n",
    "        return 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "CudaSupportError",
     "evalue": "Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBAPRO_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCudaSupportError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3d5cb5d5457e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mheaviside_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m     86\u001b[0m                       \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \"\"\"\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCUDAUFuncMechanism\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/numba/npyufunc/deviceufunc.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(cls, typemap, args, kws)\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0many_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mdev_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0mdevarys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mto_device\u001b[0;34m(self, hostary, stream)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhostary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhostary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/numba/cuda/cudadrv/devices.py\u001b[0m in \u001b[0;36m_require_cuda_context\u001b[0;34m(*args, **kws)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/numba/cuda/cudadrv/devices.py\u001b[0m in \u001b[0;36mget_context\u001b[0;34m(devnum)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCUDA\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \"\"\"\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_or_create_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/numba/cuda/cudadrv/devices.py\u001b[0m in \u001b[0;36mget_or_create_context\u001b[0;34m(self, devnum)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdevnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/numba/cuda/cudadrv/devices.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, devnum)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdevnum\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         '''\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdevnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/numba/cuda/cudadrv/devices.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# Device list is not initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Query all CUDA devices.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mnumdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             gpus = [_DeviceContextManager(driver.get_device(devid))\n\u001b[1;32m     28\u001b[0m                     for devid in range(numdev)]\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36mget_device_count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_device_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuDeviceGetCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialization_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             raise CudaSupportError(\"Error at driver init: \\n%s:\" %\n\u001b[0;32m--> 272\u001b[0;31m                                    self.initialization_error)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;31m# Find function in driver library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCudaSupportError\u001b[0m: Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBAPRO_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:"
     ]
    }
   ],
   "source": [
    "heaviside_gpu(x, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 8.27 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit heaviside_gpu(x, h0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vu lors l'introduction à **@jit**, il est possible de spécialiser une fonction vectorize en donnant les différents types sous forme de liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@vectorize(['float64(float64, float64)',\n",
    "            'float32(float32, float32)',\n",
    "            'int32(int32, int32)'], target='parallel')\n",
    "def heaviside_para(x, h0):\n",
    "    if x == 0:\n",
    "        return h0\n",
    "    elif x < 0:\n",
    "        return 0.\n",
    "    else:\n",
    "        return 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## guvectorize\n",
    "\n",
    "**guvectorize** fait exactement la même chose que **vectorize** à la seule différence que nous n'avons à aucun moment spécifié le tableau de sortie. Celui-ci est donc créé à chaque appel de la fonction. Ce qui peut avoir un coup non négligeable si nous appelons plein de fois la fonction. **guvectorize** permet de mettre le tableau de sortie dans les arguments.\n",
    "\n",
    "Reprenons notre exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import guvectorize    \n",
    "\n",
    "@guvectorize(['(float64[:], float64[:], float64[:])'], '(),()->()', target='parallel')\n",
    "def guheaviside(x, h0, y):\n",
    "    if x[0] == 0:\n",
    "        y[0] = h0[0]\n",
    "    elif x[0] < 0:\n",
    "        y[0] = 0.\n",
    "    else:\n",
    "        y[0] = 1.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.zeros_like(x)\n",
    "guheaviside(x, h0, y)\n",
    "np.all(y == numpy_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.82 ms ± 579 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit guheaviside(x, h0, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**guvectorize** permet de gérer plus facilement le parallèlisme que **vectorize** lorsque vous ne faites pas des opérations élément par élément mais que vous avez des formules un peu plus complexes.\n",
    "\n",
    "Supposons que nous voulions calculer la racine carrée de la somme des éléments au carré des éléments colonnes d'une matrice. Ces calculs peuvent se faire de manière indépendante et de façon parallèle sur chacune des lignes.\n",
    "\n",
    "Voici comment l'écrire avec **guvectorize**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numba import njit, guvectorize\n",
    "import numpy as np\n",
    "\n",
    "@njit\n",
    "def square_sum(arr):\n",
    "    a = 0.\n",
    "    for i in range(arr.size):\n",
    "        a = sqrt(a**2 + arr[i]**2)\n",
    "    return a\n",
    "\n",
    "@guvectorize([\"void(float64[:], float64[:])\"], \"(n) -> ()\", target=\"parallel\", nopython=True)\n",
    "def row_sum_gu(input_array, output_array) :\n",
    "    output_array[0] = square_sum(input_array)\n",
    "\n",
    "@njit\n",
    "def row_sum_jit(input_array, output_array) :\n",
    "    m, n = input_array.shape\n",
    "    for i in range(m) :\n",
    "        output_array[i] = square_sum(input_array[i,:])\n",
    "    return output_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508 ms ± 7.16 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "139 ms ± 7.6 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "rows = int(64)\n",
    "columns = int(1e6)\n",
    "\n",
    "input_array = np.random.random((rows, columns))\n",
    "output_array = np.zeros((rows))\n",
    "output_array2 = np.zeros((rows))\n",
    "\n",
    "# Warmup an check that they are equal \n",
    "np.allclose(row_sum_jit(input_array, output_array), row_sum_gu(input_array, output_array2))\n",
    "%timeit row_sum_jit(input_array, output_array.copy())  # 10 loops, best of 3: 130 ms per loop\n",
    "%timeit row_sum_gu(input_array, output_array.copy())   # 10 loops, best of 3: 35.7 ms per loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le calcul du carré et de la racine carrèe ont un coût de calcul important. On voit ici tout le bénéfice d'utiliser **guvectorize** pour profiter du parallèlisme.\n",
    "\n",
    "## Exercice\n",
    "\n",
    "Proposez une version de cette fonction en utilisant **guvectorize**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splint(xa, ya, y2a, x, y):\n",
    "    n = xa.shape[0]\n",
    "    for i in range(x.shape[0]):\n",
    "        klo = 0\n",
    "        khi = n-1\n",
    "        while(khi-klo) > 1:\n",
    "            k = (khi+klo) >> 1\n",
    "            if xa[k] > x[i]:\n",
    "                khi = k\n",
    "            else:\n",
    "                klo = k\n",
    "        h = xa[khi] - xa[klo]\n",
    "        a = (xa[khi]-x[i])/h    \n",
    "        b = (x[i]-xa[klo])/h\n",
    "        y[i,:] = a*ya[klo,:]+b*ya[khi,:]+((a**3-a)*y2a[klo,:]+(b**3-b)*y2a[khi,:])*h**2/6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='http://fonts.googleapis.com/css?family=Fenix' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400' rel='stylesheet' type='text/css'>\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Oswald|Raleway\" rel=\"stylesheet\" type='text/css'> \n",
       "<style>\n",
       ".prompt{\n",
       "    display: none !important;\n",
       "}\n",
       "\n",
       ".rendered_html pre {\n",
       "    border: 1px solid #f0f6f9 !important;\n",
       "}\n",
       "\n",
       ".rendered_html pre, .rendered_html code {\n",
       "    background-color: #d3d8db !important;\n",
       "    padding: 1% !important;\n",
       "    line-height: 200% !important;\n",
       "    border-radius: 10px !important;\n",
       "}\n",
       "\n",
       "div.input_area {\n",
       "    border-radius: 10px !important;\n",
       "    background-color: #e1e1e6 !important;\n",
       "}\n",
       "\n",
       "div.cell{\n",
       "        width:85% !important;\n",
       "        margin-left:5% !important;\n",
       "        /*margin-right:auto;*/\n",
       "    }\n",
       "    h1, h2, h3, h4, h5 {\n",
       "        font-family: 'Oswald', sans-serif; !important;\n",
       "        font-style: oblique !important;\n",
       "    }\n",
       "    div.text_cell_render{\n",
       "        font-family: 'Raleway', sans-serif; !important;\n",
       "        line-height: 135% !important;\n",
       "        font-size: 120% !important;\n",
       "        width:100%;/*600px;*/\n",
       "        /*margin-left:auto;*/\n",
       "        /*margin-right:auto;*/\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\" !important;\n",
       "\t\t\tfont-size: 100% !important;\n",
       "    }\n",
       "    .text_cell_render p{\n",
       "        text-align: justify !important;\n",
       "    }\n",
       "    .text_cell_render h1 {\n",
       "        font-weight: 200 !important;\n",
       "\t\tline-height: 100% !important;\n",
       "        color:#47597A !important;\n",
       "        margin-bottom: 10.em !important;\n",
       "        margin-top: 50.em !important;\n",
       "        padding-bottom: 50.em !important;\n",
       "        padding-top: 50.em !important;\n",
       "        display: block !important;\n",
       "        font-size: 300% !important;\n",
       "        text-align: center !important;\n",
       "        border-bottom: 1px solid #47597A !important;\n",
       "        border-top: 1px solid #47597A !important;\n",
       "    }\n",
       "    .text_cell_render h2 {\n",
       "        font-weight: 200 !important;\n",
       "\t\tline-height: 100% !important;\n",
       "        color:#47597A !important;\n",
       "        margin-bottom: 0.5em !important;\n",
       "        margin-top: 0.5em !important;\n",
       "        display: block !important;\n",
       "        font-size: 200% !important;\n",
       "        border-bottom: 1px solid #47597A !important;\n",
       "    }\n",
       "    .text_cell_render h3 {\n",
       "        font-weight: 200 !important;\n",
       "\t\tline-height: 100% !important;\n",
       "        color:#47597A !important;\n",
       "        margin-bottom: 0.5em !important;\n",
       "        margin-top: 0.5em !important;\n",
       "        display: block !important;\n",
       "        font-size: 200% !important;\n",
       "    }\n",
       "    .text_cell_render h4 {\n",
       "        font-style: italic !important;\n",
       "        font-weight: bold !important;\n",
       "\t\tline-height: 100% !important;\n",
       "        color:#47597A !important;\n",
       "        display: block !important;\n",
       "        font-size: 100% !important;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 200 !important;\n",
       "\t\tline-height: 100% !important;\n",
       "        color:#47597A !important;\n",
       "        margin-bottom: 0.5em !important;\n",
       "        margin-top: 0.5em !important;\n",
       "        display: block !important;\n",
       "        font-size: 100% !important;\n",
       "    }\n",
       "    .text_cell_render ul {\n",
       "\tlist-style-type: disc !important;\n",
       "\tcolor:#47597A !important;\n",
       "    }\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 ) !important;\n",
       "        }\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"],\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute this part to modify the css style\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"./style/custom.css\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
